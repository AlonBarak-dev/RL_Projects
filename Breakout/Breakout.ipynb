{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from colabgymrender.recorder import Recorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enviorment_name = \"ALE/Breakout-v5\"\n",
    "env = gym.make(enviorment_name)\n",
    "env = Recorder(env, './video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:4.0\n",
      "Episode:2 Score:4.0\n",
      "Episode:3 Score:0.0\n",
      "Episode:4 Score:1.0\n",
      "Episode:5 Score:3.0\n"
     ]
    }
   ],
   "source": [
    "# Test the enviorment\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(\"Episode:{} Score:{}\".format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env(enviorment_name, n_envs=4, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "a2c_model = A2C('CnnPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\A2C_2\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 237      |\n",
      "|    ep_rew_mean        | 1.93     |\n",
      "| time/                 |          |\n",
      "|    fps                | 193      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.345    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0844  |\n",
      "|    value_loss         | 0.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 237      |\n",
      "|    ep_rew_mean        | 1.86     |\n",
      "| time/                 |          |\n",
      "|    fps                | 195      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.84     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.155   |\n",
      "|    value_loss         | 0.0994   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 238      |\n",
      "|    ep_rew_mean        | 1.87     |\n",
      "| time/                 |          |\n",
      "|    fps                | 195      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.23    |\n",
      "|    explained_variance | 0.951    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.172   |\n",
      "|    value_loss         | 0.0457   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 241      |\n",
      "|    ep_rew_mean        | 1.99     |\n",
      "| time/                 |          |\n",
      "|    fps                | 198      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0.872    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.0349  |\n",
      "|    value_loss         | 0.0544   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 268      |\n",
      "|    ep_rew_mean        | 2.89     |\n",
      "| time/                 |          |\n",
      "|    fps                | 202      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.728    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.244    |\n",
      "|    value_loss         | 0.132    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | 3.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.568   |\n",
      "|    explained_variance | 0.113    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.0813   |\n",
      "|    value_loss         | 0.337    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 310      |\n",
      "|    ep_rew_mean        | 4.71     |\n",
      "| time/                 |          |\n",
      "|    fps                | 210      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.292   |\n",
      "|    explained_variance | 0.719    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.00867 |\n",
      "|    value_loss         | 0.328    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 319      |\n",
      "|    ep_rew_mean        | 5.12     |\n",
      "| time/                 |          |\n",
      "|    fps                | 212      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.474   |\n",
      "|    explained_variance | 0.982    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.00382 |\n",
      "|    value_loss         | 0.0263   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 339      |\n",
      "|    ep_rew_mean        | 6.17     |\n",
      "| time/                 |          |\n",
      "|    fps                | 214      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.448   |\n",
      "|    explained_variance | 0.921    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.044   |\n",
      "|    value_loss         | 0.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 350      |\n",
      "|    ep_rew_mean        | 6.63     |\n",
      "| time/                 |          |\n",
      "|    fps                | 218      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | -0.00311 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.25    |\n",
      "|    value_loss         | 0.195    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 362      |\n",
      "|    ep_rew_mean        | 6.6      |\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.936   |\n",
      "|    explained_variance | 0.452    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.171    |\n",
      "|    value_loss         | 0.266    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 386      |\n",
      "|    ep_rew_mean        | 7.14     |\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.397   |\n",
      "|    explained_variance | 0.753    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.263   |\n",
      "|    value_loss         | 0.644    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 409      |\n",
      "|    ep_rew_mean        | 7.64     |\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.601   |\n",
      "|    explained_variance | 0.923    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.0505  |\n",
      "|    value_loss         | 0.243    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 429      |\n",
      "|    ep_rew_mean        | 8.14     |\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.584   |\n",
      "|    explained_variance | 0.974    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.0527  |\n",
      "|    value_loss         | 0.0277   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 452      |\n",
      "|    ep_rew_mean        | 8.85     |\n",
      "| time/                 |          |\n",
      "|    fps                | 227      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.853   |\n",
      "|    explained_variance | 0.555    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.0493  |\n",
      "|    value_loss         | 0.0773   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 484      |\n",
      "|    ep_rew_mean        | 9.87     |\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.479   |\n",
      "|    explained_variance | 0.873    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.0029   |\n",
      "|    value_loss         | 0.0613   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 497      |\n",
      "|    ep_rew_mean        | 10.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.336   |\n",
      "|    explained_variance | 0.852    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.141    |\n",
      "|    value_loss         | 0.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 498      |\n",
      "|    ep_rew_mean        | 10.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0829  |\n",
      "|    explained_variance | 0.863    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.00466 |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 515      |\n",
      "|    ep_rew_mean        | 10.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.511   |\n",
      "|    explained_variance | 0.976    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.149   |\n",
      "|    value_loss         | 0.0417   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 531      |\n",
      "|    ep_rew_mean        | 11.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.545   |\n",
      "|    explained_variance | 0.957    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.018    |\n",
      "|    value_loss         | 0.0301   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 538      |\n",
      "|    ep_rew_mean        | 11.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 235      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.422   |\n",
      "|    explained_variance | 0.627    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.11     |\n",
      "|    value_loss         | 0.262    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 538      |\n",
      "|    ep_rew_mean        | 11.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 236      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.31    |\n",
      "|    explained_variance | 0.899    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.058   |\n",
      "|    value_loss         | 0.088    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 542      |\n",
      "|    ep_rew_mean        | 11.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 237      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.391   |\n",
      "|    explained_variance | 0.756    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.0367   |\n",
      "|    value_loss         | 0.0658   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 562      |\n",
      "|    ep_rew_mean        | 11.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.247   |\n",
      "|    explained_variance | 0.981    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.0678  |\n",
      "|    value_loss         | 0.0679   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 572      |\n",
      "|    ep_rew_mean        | 12.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 238      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.13    |\n",
      "|    explained_variance | 0.956    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.0582  |\n",
      "|    value_loss         | 0.0663   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 577      |\n",
      "|    ep_rew_mean        | 12.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 239      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.5     |\n",
      "|    explained_variance | 0.996    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.0304   |\n",
      "|    value_loss         | 0.0087   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 579      |\n",
      "|    ep_rew_mean        | 12.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.174   |\n",
      "|    explained_variance | 0.949    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.0189  |\n",
      "|    value_loss         | 0.0742   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 588      |\n",
      "|    ep_rew_mean        | 12.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.655   |\n",
      "|    explained_variance | 0.765    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0243  |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 587      |\n",
      "|    ep_rew_mean        | 12.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 241      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.623   |\n",
      "|    explained_variance | 0.961    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.0565   |\n",
      "|    value_loss         | 0.0264   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 597      |\n",
      "|    ep_rew_mean        | 13.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.257   |\n",
      "|    explained_variance | 0.955    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.0209  |\n",
      "|    value_loss         | 0.0488   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 597      |\n",
      "|    ep_rew_mean        | 13.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 242      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.263   |\n",
      "|    explained_variance | 0.887    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.129   |\n",
      "|    value_loss         | 0.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 595      |\n",
      "|    ep_rew_mean        | 13.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 243      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.186   |\n",
      "|    explained_variance | 0.841    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.0606  |\n",
      "|    value_loss         | 0.121    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 576      |\n",
      "|    ep_rew_mean        | 12.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 243      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.29    |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.0369   |\n",
      "|    value_loss         | 0.0445   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 548      |\n",
      "|    ep_rew_mean        | 12.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 243      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.171   |\n",
      "|    explained_variance | 0.574    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0128   |\n",
      "|    value_loss         | 0.303    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 544      |\n",
      "|    ep_rew_mean        | 12       |\n",
      "| time/                 |          |\n",
      "|    fps                | 243      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0926  |\n",
      "|    explained_variance | 0.933    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.00509 |\n",
      "|    value_loss         | 0.073    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 543      |\n",
      "|    ep_rew_mean        | 11.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.173   |\n",
      "|    explained_variance | 0.923    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.00834  |\n",
      "|    value_loss         | 0.155    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 546      |\n",
      "|    ep_rew_mean        | 11.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.378   |\n",
      "|    explained_variance | 0.949    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.0736  |\n",
      "|    value_loss         | 0.0546   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 557      |\n",
      "|    ep_rew_mean        | 12.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 244      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.446   |\n",
      "|    explained_variance | 0.935    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.015    |\n",
      "|    value_loss         | 0.0697   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 569      |\n",
      "|    ep_rew_mean        | 12.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.124   |\n",
      "|    explained_variance | 0.94     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.0337  |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 601      |\n",
      "|    ep_rew_mean        | 13.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 325      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.428   |\n",
      "|    explained_variance | 0.772    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.0507  |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 629      |\n",
      "|    ep_rew_mean        | 14.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.222   |\n",
      "|    explained_variance | 0.983    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.0337  |\n",
      "|    value_loss         | 0.0229   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 643      |\n",
      "|    ep_rew_mean        | 15.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.321   |\n",
      "|    explained_variance | 0.751    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.0752  |\n",
      "|    value_loss         | 0.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 649      |\n",
      "|    ep_rew_mean        | 15.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0549  |\n",
      "|    explained_variance | 0.925    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.0194   |\n",
      "|    value_loss         | 0.078    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 664      |\n",
      "|    ep_rew_mean        | 15.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.239   |\n",
      "|    explained_variance | 0.889    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.00716 |\n",
      "|    value_loss         | 0.174    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 656      |\n",
      "|    ep_rew_mean        | 15.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 246      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 364      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.269   |\n",
      "|    explained_variance | 0.936    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.0649  |\n",
      "|    value_loss         | 0.0508   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 649      |\n",
      "|    ep_rew_mean        | 15       |\n",
      "| time/                 |          |\n",
      "|    fps                | 247      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 372      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.231   |\n",
      "|    explained_variance | 0.986    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.0218  |\n",
      "|    value_loss         | 0.0139   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 647      |\n",
      "|    ep_rew_mean        | 14.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 247      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 379      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.139   |\n",
      "|    explained_variance | 0.956    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.0162   |\n",
      "|    value_loss         | 0.0458   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 650      |\n",
      "|    ep_rew_mean        | 14.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 247      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 387      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.204   |\n",
      "|    explained_variance | 0.984    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.0272   |\n",
      "|    value_loss         | 0.0243   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 653      |\n",
      "|    ep_rew_mean        | 14.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 248      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 394      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.141   |\n",
      "|    explained_variance | 0.947    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.00561  |\n",
      "|    value_loss         | 0.0111   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 655      |\n",
      "|    ep_rew_mean        | 14.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 248      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.247   |\n",
      "|    explained_variance | 0.985    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.0032  |\n",
      "|    value_loss         | 0.0325   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x1755fc61be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the a2c model\n",
    "a2c_model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_path = os.path.join('Training', 'saved_models', 'A2C_Breakout_Model')\n",
    "a2c_model.save(a2c_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single enviorment obj\n",
    "env = make_atari_env(enviorment_name, n_envs=1, seed=0)\n",
    "# keep the num of stack as 4 so the evaluation will success\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.5, 2.5787593916455256)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(a2c_model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different algorithm - PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env(enviorment_name, n_envs=4, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# create ppo model instace\n",
    "ppo_model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 235      |\n",
      "|    ep_rew_mean     | 1.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 227      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 257        |\n",
      "|    ep_rew_mean          | 2.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 139        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 117        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02326653 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | -0.0654    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0161    |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    value_loss           | 0.0645     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 296        |\n",
      "|    ep_rew_mean          | 3.47       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 125        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02443381 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.59       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0265    |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 336         |\n",
      "|    ep_rew_mean          | 4.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023233475 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0176     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 412         |\n",
      "|    ep_rew_mean          | 6.72        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025670849 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00446     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0524     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 468        |\n",
      "|    ep_rew_mean          | 8.39       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 424        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03449443 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.662      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0424    |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0542    |\n",
      "|    value_loss           | 0.151      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 508        |\n",
      "|    ep_rew_mean          | 10.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 494        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03707508 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.733      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00702   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0513    |\n",
      "|    value_loss           | 0.123      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 530        |\n",
      "|    ep_rew_mean          | 11         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 563        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04210458 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.77       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0368    |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0575    |\n",
      "|    value_loss           | 0.102      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 550         |\n",
      "|    ep_rew_mean          | 11.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 633         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044696074 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0349     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0598     |\n",
      "|    value_loss           | 0.0931      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 574         |\n",
      "|    ep_rew_mean          | 12.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 702         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050711446 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0498     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.062      |\n",
      "|    value_loss           | 0.0841      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 587         |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 771         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061213132 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0896     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0641     |\n",
      "|    value_loss           | 0.0787      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 594        |\n",
      "|    ep_rew_mean          | 12.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 840        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06651756 |\n",
      "|    clip_fraction        | 0.403      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.993     |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0706    |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0685    |\n",
      "|    value_loss           | 0.0879     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 594        |\n",
      "|    ep_rew_mean          | 12.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 117        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 910        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07752325 |\n",
      "|    clip_fraction        | 0.423      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.953     |\n",
      "|    explained_variance   | 0.814      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0697    |\n",
      "|    value_loss           | 0.0755     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1756b153940>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "ppo_model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('Training', 'saved_models', 'PPO_model_Breakout2')\n",
    "ppo_model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single enviorment obj\n",
    "env = make_atari_env(enviorment_name, n_envs=1, seed=0)\n",
    "# keep the num of stack as 4 so the evaluation will success\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.7, 3.257299494980466)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(ppo_model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Trying both A2C and PPO Model-free algorithms on the Atari enviorment with a speed up of x4 <br>\n",
    "with total timestamps of 100,000 each, we can see that the difference isn't big between the result. <br>\n",
    "\n",
    "A2C - 16.5 points per game on average <br>\n",
    "PPO - 15.7 point per game on average <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0294e00e9c4fb5f941406d31e07ab492d376d403b8551c058698d1ba9a07d7e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
